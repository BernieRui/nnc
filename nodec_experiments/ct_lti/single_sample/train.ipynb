{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT-LTI: Single Sample Training\n",
    "This notebook contains the adaption from the training script.\n",
    "It can produced data for plotting and trains one NODEC and one OC baselines on a given control setting.\n",
    "This script has not be tested on cpu only machines so please use with care and edit any gpu induced errors.\n",
    "\n",
    "Furthermore, please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/ct_lti/gen_parameters.py```.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../../')\n",
    "\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm.cli import tqdm\n",
    "\n",
    "from nnc.controllers.baselines.ct_lti.dynamics import ContinuousTimeInvariantDynamics\n",
    "from nnc.controllers.baselines.ct_lti.optimal_controllers import ControllabiltyGrammianController\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, drivers_to_tensor\n",
    "from nnc.helpers.graph_helper import load_graph\n",
    "from nnc.helpers.torch_utils.evaluators import FixedInteractionEvaluator\n",
    "from nnc.helpers.torch_utils.losses import FinalStepMSE\n",
    "from nnc.helpers.torch_utils.trainers import NODECTrainer\n",
    "\n",
    "from nnc.helpers.torch_utils.file_helpers import read_tensor_from_collection\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.helpers.torch_utils.nn_architectures.fully_connected import StackedDenseTimeControl\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the data folder and the device\n",
    "experiment_data_folder = '../../../../data/parameters/ct_lti/'\n",
    "graph='lattice'\n",
    "device = 'cuda:0' #'cuda:0' if cuda is available to speed up experiements by a lot.\n",
    "\n",
    "results_data_folder = '../../../../results/ct_lti/single_sample/'\n",
    "os.makedirs(results_data_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph data\n",
    "graph_folder = experiment_data_folder+graph+'/'\n",
    "adj_matrix = torch.load(graph_folder+'adjacency.pt').to(dtype=torch.float, device=device)\n",
    "n_nodes = adj_matrix.shape[0]\n",
    "drivers = torch.load(graph_folder + 'drivers.pt').to(dtype=torch.long, device=device)\n",
    "n_drivers = len(drivers)\n",
    "pos = pd.read_csv(graph_folder + 'pos.csv').set_index('index').values\n",
    "driver_matrix = drivers_to_tensor(n_nodes, drivers).to(dtype=torch.float, device=device)\n",
    "\n",
    "# select dynamics type and initial-target states\n",
    "dyn = ContinuousTimeInvariantDynamics(adj_matrix, driver_matrix)\n",
    "\n",
    "target_states = torch.load(graph_folder+'target_states.pt').to(dtype=torch.float, device=device)\n",
    "initial_states = torch.load(experiment_data_folder+'init_states.pt').to(dtype=torch.float, device=device)\n",
    "\n",
    "# we pick sample 24 as it looks  nice\n",
    "current_sample_id = 24\n",
    "\n",
    "# we load the corresponding initial and target states\n",
    "x0 = initial_states[current_sample_id].unsqueeze(0) # we introduce a singular batch dimension\n",
    "xstar = target_states[current_sample_id].unsqueeze(0) # we introduce a singular batch dimension\n",
    "\n",
    "# total time for control\n",
    "total_time=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the states using plotly. Square lattice can be directly embedded on a heatmap.\n",
    "\n",
    "initial_state_fig =  go.Heatmap(z=x0.view(32,32).cpu().numpy(), zmin=-1, zmax=1, \n",
    "                               colorscale='Plasma', \n",
    "                               colorbar=None, showscale=False, showlegend=False)\n",
    "target_state_fig =   go.Heatmap(z=xstar.view(32,32).cpu().numpy(), zmin=-1, zmax=1, colorscale='Plasma',  \n",
    "                                colorbar=dict(title ='State Value'))\n",
    "fig = make_subplots(cols=2, subplot_titles=(\"Initials State\", \"Target State\"))\n",
    "fig.add_trace(initial_state_fig, row=1, col=1)\n",
    "fig.add_trace(target_state_fig, row=1, col=2)\n",
    "\n",
    "fig.update_layout(dict(\n",
    "                       width = 500, \n",
    "                       height = 200, \n",
    "                       margin = dict(t=20, b=2, l=2, r=50),\n",
    "                      )\n",
    "                 )\n",
    "fig.update_xaxes(visible=False)\n",
    "fig.update_yaxes(visible=False)\n",
    "fig.data[0].showscale = False\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Control \n",
    "### Calculate Optimal Control Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal control parametrization\n",
    "oc = ControllabiltyGrammianController(\n",
    "    adj_matrix, # in paper symbol A\n",
    "    driver_matrix, # in paper symbol B\n",
    "    total_time, # in paper T\n",
    "    x0, # in paper x(0)\n",
    "    xstar, # in paper x^*\n",
    "    simpson_evals=100, # number of simpson evaluations\n",
    "    progress_bar=tqdm, # a progress bar on simpson evals\n",
    "    use_inverse=False, # Whether to use torch.inverse or torch.solve for grammian calculation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Optimal Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal control evaluations\n",
    "loss_fn = FinalStepMSE(xstar, total_time=total_time) # the loss function to keep during evaluation\n",
    "\n",
    "# number of interaction, if we divide T with n_interactions we get the interaction intervals reported in paper\n",
    "all_n_interactions = [50, 500, 5000] \n",
    "\n",
    "for n_interactions in all_n_interactions:\n",
    "    oc_evaluator = FixedInteractionEvaluator(\n",
    "        'oc_sample_ninter_' + str(n_interactions),\n",
    "        log_dir=results_data_folder,\n",
    "        n_interactions=n_interactions,\n",
    "        loss_fn=loss_fn,\n",
    "        ode_solver=None,\n",
    "        ode_solver_kwargs={'method' : 'dopri5'},\n",
    "        preserve_intermediate_states=False,\n",
    "        preserve_intermediate_controls=True,\n",
    "        preserve_intermediate_times=False,\n",
    "        preserve_intermediate_energies=True,\n",
    "        preserve_intermediate_losses=True,\n",
    "        preserve_params=False,\n",
    "    )\n",
    "    oc_res = oc_evaluator.evaluate(dyn, oc, x0, total_time, epoch=0)\n",
    "    oc_evaluator.write_to_file(oc_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "### Initialize Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network controller is generated here! The seed is set in an effort to improve reproducability.\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# The neural network:\n",
    "nn = StackedDenseTimeControl(n_nodes, \n",
    "                             n_drivers, \n",
    "                             n_hidden=0,#1 layer is created for 0. \n",
    "                             hidden_size=15,#*n_nodes,\n",
    "                             activation=torch.nn.functional.elu,\n",
    "                             use_bias=True\n",
    "                            ).to(x0.device)\n",
    "\n",
    "# The dynamics that allow gradient flows \n",
    "nndyn = NNCDynamics(dyn, nn).to(x0.device)\n",
    "\n",
    "# This evaluator is used to to log the parameters while training.\n",
    "nn_logger = FixedInteractionEvaluator(\n",
    "        'nn_sample_train',\n",
    "        log_dir=results_data_folder,\n",
    "        n_interactions=500,\n",
    "        loss_fn=loss_fn,\n",
    "        ode_solver=None,\n",
    "        ode_solver_kwargs={'method' : 'dopri5'},\n",
    "        preserve_intermediate_states=False,\n",
    "        preserve_intermediate_controls=False,\n",
    "        preserve_intermediate_times=False,\n",
    "        preserve_intermediate_energies=False,\n",
    "        preserve_intermediate_losses=False,\n",
    "        preserve_params=True,\n",
    "    )\n",
    "\n",
    "# The trainer following algorithm 3 from the paper appendix.\n",
    "nn_trainer = NODECTrainer(\n",
    "    nndyn,\n",
    "    x0,\n",
    "    xstar,\n",
    "    total_time,\n",
    "    obj_function=None,\n",
    "    optimizer_class = torch.optim.LBFGS,\n",
    "    optimizer_params=dict(lr=1.2,\n",
    "                          #momentum =0.5\n",
    "                          max_iter=1,\n",
    "                          max_eval=1,\n",
    "                          history_size=100\n",
    "                         ),\n",
    "    ode_solver_kwargs=dict(method='dopri5'),\n",
    "    logger=nn_logger,\n",
    "    closure=None,\n",
    "    use_adjoint=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network parameter init, we have tested Xavier and Kaiming\n",
    "# For the current example the Kaiming divided by 1000 would yield better models more often.\n",
    "# Please feel free to change, if you would like to evaluate in a single example case.\n",
    "torch.manual_seed(1)\n",
    "for name, param in nn.named_parameters():\n",
    "    if len(param.shape) > 1:\n",
    "        torch.nn.init.kaiming_normal_(param) # or torch.nn.xavier(param)\n",
    "        param = param/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train  NODEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The training process... May take a lot of time without gpu\n",
    "nndyn = nn_trainer.train_best(epochs=2500, \n",
    "                              lr_acceleration_rate=0,\n",
    "                              lr_deceleration_rate=0.9,\n",
    "                              loss_variance_tolerance=10,\n",
    "                              verbose=True\n",
    "                             )\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate NODEC\n",
    "First we evaluate the trained model for 500 and 5000 interactions, then we will evaluate it for less by loading earlier epoch parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control evaluations using the evaluator for all interactions similar to OC\n",
    "loss_fn = FinalStepMSE(xstar, total_time=total_time)\n",
    "all_n_interactions = [500, 5000] # we skip 50, because we want to use weights from earlier epoch\n",
    "for n_interactions in all_n_interactions:\n",
    "    nn_evaluator = FixedInteractionEvaluator(\n",
    "        'eval_nn_sample_ninter_' + str(n_interactions),\n",
    "        log_dir=results_data_folder,\n",
    "        n_interactions=n_interactions,\n",
    "        loss_fn=loss_fn,\n",
    "        ode_solver=None,\n",
    "        ode_solver_kwargs={'method' : 'dopri5'},\n",
    "        preserve_intermediate_states=False,\n",
    "        preserve_intermediate_controls=True,\n",
    "        preserve_intermediate_times=False,\n",
    "        preserve_intermediate_energies=True,\n",
    "        preserve_intermediate_losses=True,\n",
    "        preserve_params=False,\n",
    "    )\n",
    "    nn_res = nn_evaluator.evaluate(dyn, nndyn.nnc, x0, total_time, epoch=0)\n",
    "    nn_evaluator.write_to_file(nn_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and save for the highest interaction interval $10^{-2}$ with 50 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndyn2 = deepcopy(nndyn)\n",
    "n_interactions = 50\n",
    "high_interval_epoch = 100\n",
    "params = read_tensor_from_collection(results_data_folder + 'nn_sample_train/' + 'epochs', \n",
    "                                     'nodec_params/ep_'+str(high_interval_epoch)+'.pt')\n",
    "\n",
    "nndyn2.nnc.load_state_dict(params)\n",
    "nn_evaluator = FixedInteractionEvaluator(\n",
    "    'eval_nn_sample_ninter_' + str(n_interactions),\n",
    "    log_dir=results_data_folder,\n",
    "    n_interactions=n_interactions,\n",
    "    loss_fn=loss_fn,\n",
    "    ode_solver=None,\n",
    "    ode_solver_kwargs={'method' : 'dopri5'},\n",
    "    preserve_intermediate_states=False,\n",
    "    preserve_intermediate_controls=True,\n",
    "    preserve_intermediate_times=False,\n",
    "    preserve_intermediate_energies=True,\n",
    "    preserve_intermediate_losses=True,\n",
    "    preserve_params=False,\n",
    ")\n",
    "nn_res = nn_evaluator.evaluate(dyn, nndyn2.nnc, x0, total_time, epoch=0)\n",
    "nn_evaluator.write_to_file(nn_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
