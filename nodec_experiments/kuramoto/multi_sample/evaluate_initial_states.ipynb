{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuramoto: Fig. 6c\n",
    "\n",
    "\n",
    "This script uses a trained model and the feedback control to create evaluation trajectories over many possible intial states sampled from a uniform distribution in $[0,\\pi]$.\n",
    "\n",
    "If you replace the distribution you many notice the robustess of NODEC to initial state settings.\n",
    "\n",
    "Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/kuramoto/gen_parameters.py```.\n",
    "\n",
    "Please also make sure that a training proceedure has produced results in the corresponding paths used in plot and table scripts.\n",
    "Running ```nodec_experiments/kuramoto/train.ipynb``` with default paths is expected to generate at the requiered location for the plots and table scripts in each folder.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../../')\n",
    "\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.controllers.baselines.oscillators.dynamics import AdditiveControlKuramotoDynamics\n",
    "from nnc.controllers.baselines.oscillators.optimal_controllers import KuramotoFeedbackControl\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, maximum_matching_drivers, drivers_to_tensor\n",
    "from nnc.helpers.torch_utils.oscillators import order_parameter_cos\n",
    "from nnc.helpers.torch_utils.numerics import faster_adj_odeint\n",
    "from nnc.helpers.plot_helper import ColorRegistry, base_layout\n",
    "from nnc.helpers.torch_utils.evaluators import FixedInteractionEvaluator\n",
    "\n",
    "from tqdm.cli import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load main parameters and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters, such as device, float precision and whether a pre-trained model is used.\n",
    "device = 'cpu'\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Parameters for the graph\n",
    "data_folder = '../../../../data/parameters/kuramoto/'\n",
    "graph = 'erdos_renyi'\n",
    "graph_folder = data_folder + graph + '/'\n",
    "\n",
    "training_results_folder = '../../../../data/results/kuramoto/erdos_renyi/'\n",
    "\n",
    "A = torch.load(graph_folder + 'adjacency.pt', map_location=device).float() # adjacency matrix\n",
    "G = nx.from_numpy_matrix(A.numpy())\n",
    "n_nodes = G.number_of_nodes()\n",
    "mean_degree = np.mean(list(dict(G.degree()).values()))\n",
    "\n",
    "A = A.to(device, dtype) # adjacency\n",
    "L = A.sum(-1).diag() - A # laplacian\n",
    "\n",
    "# to save results\n",
    "results_folder = '../../../../results/kuramoto/' + graph + '/'\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "os.makedirs(results_folder+'/sample_results/nodec', exist_ok=True)\n",
    "os.makedirs(results_folder+'/sample_results/fc', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dynamics dependendent variables and states\n",
    "coupling_constants = torch.load(data_folder + 'coupling_constants.pt', map_location=device).to(device, dtype)\n",
    "frustration_constants = torch.load(data_folder + 'frustration_constants.pt', map_location=device).to(device, dtype)\n",
    "natural_frequencies = torch.load(data_folder + 'nominal_angular_velocities.pt', map_location=device).to(device, dtype)\n",
    "K = coupling_constants[2].item() # coupling constant, index 2 should be 0.4\n",
    "frustration_constant = frustration_constants[0] # we use no frustration for this example\n",
    "dynamics_params_folder = graph_folder + 'dynamics_parameters/coupling_' + '{:.1f}'.format(K) + '/'\n",
    "\n",
    "\n",
    "x0 = 2*math.pi*torch.rand([100, n_nodes]).to(device=device, dtype=dtype) # you can try other distribution or\n",
    "# initial states as well here.\n",
    "\n",
    "\n",
    "# to avoid using extra memory we load the driver vector and use element-wise multiplication instead of the driver matrix.\n",
    "gain_vector = torch.load(dynamics_params_folder + 'driver_vector.pt', map_location=device).to(device, dtype)\n",
    "driver_nodes = torch.nonzero(gain_vector).cpu().numpy().flatten().tolist()\n",
    "driver_percentage = len(driver_nodes)/len(gain_vector)\n",
    "steady_state = torch.load(dynamics_params_folder + 'steady_state.pt', map_location=device).to(device, dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Controller parameters\n",
    "# Feedback Control\n",
    "feedback_control_constant = 10\n",
    "\n",
    "# Neural Network training\n",
    "n_hidden_units = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current experiment info:')\n",
    "print('\\t Loaded ' + graph + 'graph with: ' + str(n_nodes) + ' nodes and ' + str(G.number_of_edges()) + ' edges.' )\n",
    "print('\\t Coupling Constant: ' + str(K))\n",
    "print('\\t Frustration Constant: ' + str(frustration_constant.item()))\n",
    "print('\\t Natural Frequencies: mean: ' + str(natural_frequencies.mean().item()) + ' variance: ' + str(natural_frequencies.var().item()) )\n",
    "print('\\t Ratio of driver node vs total nodes: '  + str(len(driver_nodes)/n_nodes))\n",
    "print('\\t Feedback Control Constant: '  + str(feedback_control_constant))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the dynamics:\n",
    "dyn = AdditiveControlKuramotoDynamics(\n",
    "    A, \n",
    "    K, \n",
    "    natural_frequencies,\n",
    "    frustration_constant=frustration_constant\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same architecture as in train\n",
    "class EluFeedbackControl(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Very simple Elu architecture for control of linear systems\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes, n_drivers, driver_matrix, n_hidden=3):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(n_nodes,n_hidden)\n",
    "        self.linear_h1 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_final = torch.nn.Linear(n_hidden, n_drivers)\n",
    "        self.driver_matrix = driver_matrix\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        :param t: A scalar or a batch with scalars\n",
    "        :param x: input_states for all nodes\n",
    "        :return:\n",
    "        \"\"\"     \n",
    "        u = self.linear(torch.sin(x))\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_h1(u)\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_final(u)\n",
    "        # we multiply by the nn driver matrix to generate the control signal\n",
    "        u = (self.driver_matrix@u.unsqueeze(-1)).squeeze(-1)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the driver vector back to a matrix and convert the non-zero elements to 1, so that the neural network is agnostic of the exact gain values.\n",
    "driver_matrix = drivers_to_tensor(A.shape[-1], driver_nodes).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained models parameters\n",
    "neural_net = EluFeedbackControl(n_nodes, len(driver_nodes), \n",
    "                                driver_matrix,\n",
    "                                n_hidden=n_hidden_units\n",
    "                               ).to(dtype=dtype, device=device)\n",
    "neural_net.load_state_dict(torch.load(training_results_folder +'trained_model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the evaluation model\n",
    "evaluation_steps = 5000\n",
    "evalu = FixedInteractionEvaluator(\n",
    "    exp_id='kuramoto_er',\n",
    "    log_dir=None,\n",
    "    n_interactions= evaluation_steps, # neither control works consistently for less than 2-3k steps\n",
    "    loss_fn=lambda t,x: torch.tensor(order_parameter_cos(x[-1].cpu().detach())).mean(),\n",
    "    ode_solver=None,\n",
    "    ode_solver_kwargs={},\n",
    "    preserve_intermediate_states=True,\n",
    "    preserve_intermediate_controls=True,\n",
    "    preserve_intermediate_times=True,\n",
    "    preserve_intermediate_energies=True,\n",
    "    preserve_intermediate_losses=True,\n",
    "    preserve_params=False,\n",
    "    preserve_init_loss = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of both baselines on 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "nn_contorl_fun = lambda t,x: neural_net(t, x)\n",
    "fc_contorl_fun = lambda t,x: (feedback_control_constant*gain_vector*torch.sin(-x)).detach()\n",
    "total_time = 150\n",
    "\n",
    "progress_bar = tqdm(range(n_samples))\n",
    "for i in progress_bar:\n",
    "    x0 = torch.rand([1, n_nodes], device='cuda', requires_grad = False)\n",
    "    x0 = x0%(2*math.pi)\n",
    "    with torch.no_grad():\n",
    "        nnres = evalu.evaluate(dyn, \n",
    "                               nn_contorl_fun, \n",
    "                               x0.cpu(), \n",
    "                               total_time, \n",
    "                               -1\n",
    "                              )\n",
    "        torch.save(nnres, results_folder + 'nodec/sample_'+str(i)+'.pt')\n",
    "        fcres =  evalu.evaluate(dyn, \n",
    "                               fc_contorl_fun, \n",
    "                               x0.cpu(), \n",
    "                               total_time, \n",
    "                               -1\n",
    "                              )\n",
    "        torch.save(fcres, results_folder + 'fc/sample_'+str(i)+'.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
