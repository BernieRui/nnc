{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIRX: NODEC Training\n",
    "\n",
    "\n",
    "Baseline comparion in terms of total loss and energy.\n",
    "\n",
    "To run this script:\n",
    "1. Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/sirx/gen_parameters.py```.\n",
    "\n",
    "2. The scripts below:\n",
    " - ```nodec_experiments/sirx/sirx.py```\n",
    " - ```nodec_experiments/sirx/rl_utils.py```\n",
    " - ```nodec_experiments/sirx/sirx_utils.py```\n",
    "contain very important utilities for running training , evaluation and plotting scripts. Please make sure that they are available in the python path when running experiments.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "\n",
    "SIRX experiments are briefly presented in this notebook.\n",
    "This code was developed after CT-LTI and there was not enough time to be included in the main repository.\n",
    "It has been tested only in large networks.\n",
    "Please run it either in the provided lattice setting generate a graph that is large enough. \n",
    "For a smaller graph you might need to pick recovery and infection rate parameters that are smaller:\n",
    "E.g. infection rate gamma = 8 us too high for a 16 node graph.\n",
    "The experimental code will be moved to the main nnc repo code soon\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "from plotly import figure_factory as ff\n",
    "\n",
    "from sirx import SIRDelta, GCNNControl, flat_to_channels, neighborhood_mask\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "import timeit\n",
    "from tqdm.cli import tqdm\n",
    "\n",
    "# Here we use a custom trajectory evaluator that was used as the basis of the FixedIntervalEvaluator\n",
    "from sirx_utils import trajectory_eval\n",
    "from plotly import express as px\n",
    "\n",
    "\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.helpers.torch_utils.graphs import drivers_to_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and data\n",
    "Plese change to ```'cuda:0'``` to use a gpu or ```'cpu'``` to use the cpu.\n",
    "Here we load the adjacency matrix of a square lattice with $1024$ nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = 'lattice'\n",
    "parameters_folder = '../../../data/parameters/sirx/'\n",
    "results_folder = '../../../results/sirx/'+graph+'/'\n",
    "\n",
    "graph_parameters_folder = parameters_folder + '/' + 'lattice' + '/'\n",
    "\n",
    "adjacency_matrix = torch.load(graph_parameters_folder + 'adjacency.pt', map_location=device).to(dtype)\n",
    "n_nodes = adjacency_matrix.shape[-1]\n",
    "drivers = torch.load(graph_parameters_folder + 'drivers.pt', map_location='cpu').to(torch.long)\n",
    "driver_matrix = drivers_to_tensor(n_nodes, drivers).to(dtype=dtype, device=device)\n",
    "alpha = adjacency_matrix\n",
    "beta = driver_matrix\n",
    "side_size = int(np.sqrt(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamics Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.load(graph_parameters_folder + 'initial_state.pt', map_location=device).to(device=device, dtype=dtype)\n",
    "target_subgraph = torch.load(graph_parameters_folder + 'target_subgraph_nodes.pt', map_location=device)\n",
    "dynamics_params = torch.load(graph_parameters_folder + 'dynamics_parameters.pt', map_location=device)\n",
    "# budget and rates need to be choosen according to graph size\n",
    "budget = dynamics_params['budget']\n",
    "infection_rate = dynamics_params['infection_rate']\n",
    "recovery_rate = dynamics_params['recovery_rate']\n",
    "total_time = 5 # determined via no control testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sirx_dyn = SIRDelta(\n",
    "             adjacency_matrix=alpha,\n",
    "             infection_rate=infection_rate,\n",
    "             recovery_rate=recovery_rate,\n",
    "             driver_matrix=beta,\n",
    "             k_0=0.0,\n",
    "            ).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, ninds = neighborhood_mask(alpha)\n",
    "in_preprocessor = lambda x: flat_to_channels(x, n_nodes=n_nodes, mask=mask, inds=ninds)\n",
    "cnet = GCNNControl(alpha, \n",
    "                   beta, \n",
    "                   input_preprocessor=in_preprocessor,\n",
    "                   budget=budget, \n",
    "                   in_channels=4, \n",
    "                   feat_channels=5).to(device=device, dtype=dtype)\n",
    "cd = NNCDynamics(sirx_dyn, cnet).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points = 50 # to check for loss\n",
    "\n",
    "best_model = [cnet]\n",
    "best_loss = [np.inf]\n",
    "c_model =  [cnet]\n",
    "\n",
    "cnet = best_model[0]\n",
    "lr = 0.07\n",
    "optim = torch.optim.Adam(cnet.parameters(), lr=lr)\n",
    "\n",
    "learning_curve = []\n",
    "pbar =  tqdm(range(100), postfix=dict(peak_position = 0, peak_infection = 0, now_loss = 0))\n",
    "for i in pbar:\n",
    "    crit = torch.nn.MSELoss()\n",
    "    now_loss = []\n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "        allx = odeint(cd, x0, t=torch.linspace(0, total_time, sample_points).to(device, dtype=dtype), method='dopri5')\n",
    "\n",
    "        peak_point = torch.max(allx[:, :, target_subgraph].mean(-1),0)\n",
    "\n",
    "        sel_losses = peak_point[1].cpu().numpy().tolist()\n",
    "\n",
    "        x_reached = allx[sel_losses, :, :].squeeze(0)\n",
    "\n",
    "        l = crit(x_reached[:, target_subgraph], torch.zeros_like(x_reached[:, target_subgraph]).detach())\n",
    "        learning_curve.append(l.item())\n",
    "\n",
    "        l.backward(retain_graph=False)\n",
    "        now_loss.append(l.cpu().detach().item())\n",
    "        pbar.set_postfix(dict(peak_position = peak_point[1].cpu().detach().item(), \n",
    "                  peak_infection = peak_point[0].cpu().detach().item()),\n",
    "                  now_loss = l.item())\n",
    "        return l\n",
    "\n",
    "    def closee():\n",
    "        lll = optim.step(closure)\n",
    "\n",
    "    try: \n",
    "        closee()\n",
    "    except AssertionError:\n",
    "        print('possible instability due to stiffness!')\n",
    "        cd.control_net = best_model[0]\n",
    "        cnet = best_model[0] # preservation of best model.\n",
    "        lr/=2 # Learning rate adaption.\n",
    "        optim = torch.optim.Adam(cnet.parameters(), lr=lr)\n",
    "\n",
    "    if len(now_loss) > 0 and np.mean(now_loss) < best_loss[0]:\n",
    "        best_model[0] =  copy.deepcopy(cd.nnc.neural_net)\n",
    "        best_loss[0] = np.mean(now_loss)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best model and leaning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = pd.Series(learning_curve, name='learning_curve')\n",
    "lrc.to_json(results_folder + '/nodec_learning_curve.json', orient='records')\n",
    "torch.save(best_model[0].state_dict(), results_folder + 'nodec_best.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
